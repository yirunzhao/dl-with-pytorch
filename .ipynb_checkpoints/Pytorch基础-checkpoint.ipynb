{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch的4个主要的包\n",
    "- torch 类似于numpy的通用包，可以将tensor类型转换，然后在GPU上运算\n",
    "- torch.autograd 构建计算图形并且自动获取梯度的包\n",
    "- torch.nn 神经网络库\n",
    "- torch.optim 通用优化算法的包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor称为张量，和numpy的ndarray比较相似\n",
    "\n",
    "torch中如果函数后面带了下划线_，就表示结果改变原来的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 6])\n",
      "tensor([1, 2])\n",
      "tensor([4, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([3,4])\n",
    "\n",
    "z = x.add(y)\n",
    "print(z)\n",
    "print(x)\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建tensor的方法\n",
    "- Tensor(size) 可以从list、ndarray构造tensor，这个是一个类，实际上是FloatTensor，tensor是一个函数，返回一个tensor，有这个区别\n",
    "- eye(row,col)\n",
    "- linspace(start,end,steps)\n",
    "- logspace()\n",
    "- rand/randn(size)\n",
    "- ones()\n",
    "- zeros()\n",
    "- ones_like()\n",
    "- zeros_like()\n",
    "- arange(start,end,step0\n",
    "- form_Numpy(ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.4078e-45, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2,3],[2,3,4]])\n",
    "a.size()\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 2.0000e+00, 1.8754e+28],\n",
       "        [1.6244e-07, 2.1533e+23, 1.0243e-11]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  5., 10.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,10,3) # 切成3份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3742, 0.4338, 0.6284],\n",
       "        [0.1618, 0.8930, 0.2875]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,3) # 满足均匀分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1378, -0.2036, -0.1976],\n",
       "        [ 0.0126, -1.4708,  2.4083]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,3) # 满足组标准分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(torch.randn(3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改tensor形状\n",
    "- size()\n",
    "- numel(input) 计算元素个数\n",
    "- view(shape) 修改tensor的shape，和reshape类似，但是返回的对象和源tensor共享内存，reshape生成新的tensor\n",
    "- resize()\n",
    "- item()\n",
    "- unsqueeze() 在指定维度增加一个1\n",
    "- squeeze() 在指定维度压缩一个1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4235, 0.9236, 0.7080],\n",
      "        [0.4487, 0.6863, 0.8053]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "print(x)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4235, 0.9236],\n",
       "        [0.7080, 0.4487],\n",
       "        [0.6863, 0.8053]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把x变成3x2的矩阵\n",
    "x.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4235, 0.9236, 0.7080, 0.4487, 0.6863, 0.8053])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把x展平\n",
    "y = x.view(-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4235, 0.9236, 0.7080, 0.4487, 0.6863, 0.8053]])\n",
      "torch.Size([1, 6])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# 增加一个维度\n",
    "z = torch.unsqueeze(y,axis=0)\n",
    "print(z)\n",
    "print(z.size())\n",
    "print(z.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2956, 0.5640, 0.2597, 0.3066, 0.6333, 0.6183])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,3).view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3607, -0.2859, -0.3938],\n",
      "        [ 0.2429, -1.3833, -2.3134]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(100)\n",
    "x = torch.randn(2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3607, -0.2859, -0.3938])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3938, -2.3134])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3607, 0.2429])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = x > 0\n",
    "torch.masked_select(x,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引\n",
    "- index_select(input,dim,index) 指定维度上选择\n",
    "- nonzero() 获取非0元素下标\n",
    "- masked_select() 使用mask选择\n",
    "- gather(input,dim,index) 在指定维度上选择数据，输出的shape和index相同\n",
    "- scatter_(input,dim,index,src) 是gather的反向操作，补充数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3607, -0.2859, -0.3938],\n",
      "        [ 0.2429, -1.3833, -2.3134]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3607, -1.3833, -2.3134]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "index = torch.LongTensor([[0,1,1]])\n",
    "torch.gather(x,0,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3607, -0.2859, -0.2859],\n",
      "        [-1.3833, -1.3833, -1.3833]])\n"
     ]
    }
   ],
   "source": [
    "index = torch.LongTensor([[0,1,1],[1,1,1]])\n",
    "a = torch.gather(x,1,index)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gather的输出就是index的shape，需要看dim来选择，比如第二个示例它的shape=2x3，dim=1，那么就是横着选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3607, -0.2859,  0.0000],\n",
       "        [ 0.0000, -1.3833,  0.0000]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.zeros(2,3)\n",
    "z.scatter_(1,index,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### element-wise 操作\n",
    "- add/abs\n",
    "- addcdiv(t,v,t1,t2) t1,t2按元素除之后乘以v加上t\n",
    "- addcmul(t,v,t1,t2) t1,t2按元素乘之后乘以v加上t\n",
    "- ceil/floor 向上/下取整\n",
    "- clamp(t,min,max) 把tensor的元素限制到指定区间\n",
    "- exp/log/pow\n",
    "- mul(\\*)/neg 乘法/取反\n",
    "- sigmoid/tanh/softmax\n",
    "- sign/sqrt 取符号/开根号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2759],\n",
      "        [-0.9755],\n",
      "        [ 0.4790]]) tensor([[-2.3652, -0.8047,  0.6587]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2589, -0.6946,  1.5388],\n",
       "        [-0.1110, -0.2599,  1.0078],\n",
       "        [-0.4185, -1.1637,  2.1118]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(1,3)\n",
    "t1 = torch.randn(3,1)\n",
    "t2 = torch.randn(1,3)\n",
    "print(t1,t2)\n",
    "torch.addcdiv(t,0.5,t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3172, -0.8660,  1.7482]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3172, -0.8660,  1.0000]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(t,-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归并操作\n",
    "- cumprod(t,axis) 指定维度对t进行累积\n",
    "- cumsum 指定维度对t进行累加\n",
    "- dist(a,b,p=2) 返回a,b之间的p阶范数\n",
    "- mean/median 均值/中位数\n",
    "- std/var\n",
    "- norm(t,p=2) 返回t的p阶范数\n",
    "- prod(t)/sum(t) 返回t所有元素的积/和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]])\n",
      "tensor(30.)\n",
      "tensor([[ 6., 10., 14.]]) torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.linspace(0,10,6)\n",
    "a = a.reshape((2,3))\n",
    "print(a)\n",
    "b = a.sum()\n",
    "print(b)\n",
    "# keepdim 保持1的维度\n",
    "b = a.sum(axis=0,keepdim=True)\n",
    "print(b,b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比较操作\n",
    "- eq 比较tensor是否相等\n",
    "- equal 比较tensor是否有相同的shape和值\n",
    "- ge/le/gt/lt\n",
    "- max/min(t,axis)\n",
    "- topk(t,k,axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  2.,  4.],\n",
       "        [ 6.,  8., 10.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.linspace(0,10,6).view(2,3)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([ 6.,  8., 10.]),\n",
       "indices=tensor([1, 1, 1]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 4.,  2.],\n",
       "        [10.,  8.]]),\n",
       "indices=tensor([[2, 1],\n",
       "        [2, 1]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(a,2,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵操作\n",
    "- dot(t1,t2)\n",
    "- mm(mat1,mat2)/bmm(batch1,batch2) 计算矩阵乘法/含batch的3D矩阵乘法\n",
    "- mv(t1,v1) 计算矩阵和向量的乘法\n",
    "- t 转置\n",
    "- svd(t) 计算t的SVD分解\n",
    "\n",
    "#### 注意\n",
    "- torch的dot和numpy的dot有不同，torch中是对两个1D张量进行点积运算，而numpy没有限制\n",
    "- 转置运算会导致存储空间不连续，需要使用contiguous方法转换成连续"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2])\n",
    "b = torch.tensor([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(10,(2,3))\n",
    "b = torch.randint(6,(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 9, 5],\n",
       "        [7, 3, 9]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 3, 5],\n",
       "        [3, 3, 3, 3],\n",
       "        [1, 3, 0, 1]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32, 42, 27, 32],\n",
       "        [32, 50, 30, 53]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor和Autograd\n",
    "torch.autograd包用于自动求导，为张量上的所有操作提供了自动求导功能\n",
    "\n",
    "torch.Tensor和torch.Function是autograd的两个核心类，相互连接并生成一个有向非循环图\n",
    "\n",
    "#### 自动求导的要点\n",
    "\n",
    "- 创建Leaf Node的tensor，需要使用requires_grad参数指定，默认为False，指定为True后使用backward()方法求解梯度\n",
    "- 可以使用requires_grad_()方法修改一个tensor的requires_grad属性\n",
    "- 使用.detach()或者with torch.no_grad()，不会计算tensor的梯度，经常用于评估模型、测试模型\n",
    "- 通过运算创建的tensor(不是Leaf node)，会自动赋予grad_fn属性，这个属性表示梯度函数，leaf node的grad_fn是None\n",
    "- 最后得到的tensor执行backward()方法，会自动计算各个变量的梯度，结果保存到grad属性中，计算完成后，非leaf node的梯度自动释放\n",
    "- backward()接收参数，参数应该和调用它的tensor维度相同，或者是可以broadcast的，如果tensor是一个标量，则参数可省略\n",
    "- 反向传播中间缓存会被清空，如果需要进行多次反向传播，需要制定backward中的retain_graph=True，多次反向传播的时候梯度是累加的\n",
    "\n",
    "#### 计算图\n",
    "计算图是一种有向无环图DAG，用来表示算子和变量之间的关系，算子就是运算操作。\n",
    "\n",
    "比如表达式$z=wx+b$，可以写成两个表达式$y=wx$,$z=y+b$，其中$x$,$w$,$b$是用户创建的变量，不依赖于其他变量，所以是叶子节点leaf node。为了计算leaf node的梯度，我们需要把对应tensor的requireds_grad属性设置成True\n",
    "\n",
    "调用backward()方法，会自动计算各个节点的梯度，非叶子节点的计算操作会记录在grad_fn属性中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x,w,b的requires_grad属性分别是False,True,True\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([2])\n",
    "w = torch.randn(1,requires_grad=True)\n",
    "b = torch.randn(1,requires_grad=True)\n",
    "\n",
    "y = torch.mul(w,x)\n",
    "z = torch.add(y,b)\n",
    "\n",
    "print(f'x,w,b的requires_grad属性分别是{x.requires_grad},{w.requires_grad},{b.requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y,z的requires_grad属性分别是True,True\n"
     ]
    }
   ],
   "source": [
    "print(f'y,z的requires_grad属性分别是{y.requires_grad},{z.requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "print(x.is_leaf,y.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None <MulBackward0 object at 0x7fcdfa83dc50>\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn,y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的梯度tensor([2.])，b的梯度tensor([1.])，x的梯度None\n"
     ]
    }
   ],
   "source": [
    "# 反向传播\n",
    "z.backward()\n",
    "print(f'w的梯度{w.grad}，b的梯度{b.grad}，x的梯度{x.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完成一个回归任务\n",
    "回归$y=3x^2+2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(100)\n",
    "# 在-1~1之间生成100个数据点，并且重构成100x1的tensor\n",
    "x = torch.unsqueeze(torch.linspace(-1,1,100),dim=1)\n",
    "# 生成y的数据\n",
    "y = 3*x.pow(2)+2+0.2*torch.rand(x.size())\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化权重\n",
    "w = torch.randn(1,1,dtype=torch.float,requires_grad=True)\n",
    "b = torch.zeros(1,1,dtype=torch.float,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2437]], requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0:loss=496.4938049316406,w=tensor([[0.3722]], requires_grad=True),b=tensor([[0.3040]], requires_grad=True)\n",
      "epoch50:loss=6.127558708190918,w=tensor([[1.8444]], requires_grad=True),b=tensor([[2.5226]], requires_grad=True)\n",
      "epoch100:loss=2.7781760692596436,w=tensor([[2.2252]], requires_grad=True),b=tensor([[2.3885]], requires_grad=True)\n",
      "epoch150:loss=1.311419129371643,w=tensor([[2.4759]], requires_grad=True),b=tensor([[2.2957]], requires_grad=True)\n",
      "epoch200:loss=0.6685017347335815,w=tensor([[2.6418]], requires_grad=True),b=tensor([[2.2342]], requires_grad=True)\n",
      "epoch250:loss=0.38669225573539734,w=tensor([[2.7516]], requires_grad=True),b=tensor([[2.1935]], requires_grad=True)\n",
      "epoch300:loss=0.2631677985191345,w=tensor([[2.8244]], requires_grad=True),b=tensor([[2.1666]], requires_grad=True)\n",
      "epoch350:loss=0.20902280509471893,w=tensor([[2.8725]], requires_grad=True),b=tensor([[2.1487]], requires_grad=True)\n",
      "epoch400:loss=0.18528974056243896,w=tensor([[2.9044]], requires_grad=True),b=tensor([[2.1369]], requires_grad=True)\n",
      "epoch450:loss=0.17488721013069153,w=tensor([[2.9255]], requires_grad=True),b=tensor([[2.1291]], requires_grad=True)\n",
      "epoch500:loss=0.1703275442123413,w=tensor([[2.9395]], requires_grad=True),b=tensor([[2.1239]], requires_grad=True)\n",
      "epoch550:loss=0.16832900047302246,w=tensor([[2.9487]], requires_grad=True),b=tensor([[2.1205]], requires_grad=True)\n",
      "epoch600:loss=0.1674526333808899,w=tensor([[2.9548]], requires_grad=True),b=tensor([[2.1182]], requires_grad=True)\n",
      "epoch650:loss=0.16706882417201996,w=tensor([[2.9589]], requires_grad=True),b=tensor([[2.1167]], requires_grad=True)\n",
      "epoch700:loss=0.16690053045749664,w=tensor([[2.9616]], requires_grad=True),b=tensor([[2.1157]], requires_grad=True)\n",
      "epoch750:loss=0.16682672500610352,w=tensor([[2.9634]], requires_grad=True),b=tensor([[2.1151]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "lr = 0.001\n",
    "\n",
    "for epoch in range(800):\n",
    "    y_pred = x.pow(2).mm(w) + b\n",
    "    loss = 0.5 * (y_pred - y) ** 2\n",
    "    loss = loss.sum()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= lr*w.grad\n",
    "        b -= lr*b.grad\n",
    "        \n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "        \n",
    "    if epoch % 50 == 0:\n",
    "        print(f'epoch{epoch}:loss={loss},w={w},b={b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchForDeeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
